{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\python\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Embedding, Dense, Conv1D, GlobalMaxPooling1D, Concatenate\n",
    "\n",
    "class TextCNN(Model):\n",
    "\n",
    "    def __init__(self,\n",
    "                 maxlen,\n",
    "                 max_features,\n",
    "                 embedding_dims,\n",
    "                 kernel_sizes=[3, 4, 5],\n",
    "                 class_num=4, \n",
    "                 last_activation='softmax'):  \n",
    "        super(TextCNN, self).__init__()\n",
    "        self.maxlen = maxlen\n",
    "        self.max_features = max_features\n",
    "        self.embedding_dims = embedding_dims\n",
    "        self.kernel_sizes = kernel_sizes\n",
    "        self.class_num = class_num\n",
    "        self.last_activation = last_activation\n",
    "        self.embedding = Embedding(self.max_features, self.embedding_dims, input_length=self.maxlen)\n",
    "        self.convs = []\n",
    "        self.max_poolings = []\n",
    "        for kernel_size in self.kernel_sizes:\n",
    "            self.convs.append(Conv1D(128, kernel_size, activation='relu'))\n",
    "            self.max_poolings.append(GlobalMaxPooling1D())\n",
    "        self.classifier = Dense(self.class_num, activation=self.last_activation) \n",
    "\n",
    "    def call(self, inputs):\n",
    "        if len(inputs.get_shape()) != 2:\n",
    "            raise ValueError('The rank of inputs of TextCNN must be 2, but now is %d' % len(inputs.get_shape()))\n",
    "        if inputs.get_shape()[1] != self.maxlen:\n",
    "            raise ValueError('The maxlen of inputs of TextCNN must be %d, but now is %d' % (self.maxlen, inputs.get_shape()[1]))\n",
    "        # Embedding part can try multichannel as same as origin paper\n",
    "        embedding = self.embedding(inputs)\n",
    "        convs = []\n",
    "        for i in range(len(self.kernel_sizes)):\n",
    "            c = self.convs[i](embedding)\n",
    "            c = self.max_poolings[i](c)\n",
    "            convs.append(c)\n",
    "        x = Concatenate()(convs)\n",
    "        output = self.classifier(x)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "6155 train sequences\n",
      "1319 validation sequences\n",
      "1320 test sequences\n",
      "x_train shape: (6155, 30)\n",
      "x_val shape: (1319, 30)\n",
      "x_test shape: (1320, 30)\n",
      "Build model...\n",
      "WARNING:tensorflow:From d:\\python\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\python\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Train...\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From d:\\python\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\python\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "97/97 [==============================] - 2s 8ms/step - loss: 0.5231 - accuracy: 0.4609 - val_loss: 0.4955 - val_accuracy: 0.4652\n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 0.4746 - accuracy: 0.4874 - val_loss: 0.4565 - val_accuracy: 0.5045\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 0.4361 - accuracy: 0.5503 - val_loss: 0.4505 - val_accuracy: 0.5106\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 0.4181 - accuracy: 0.5807 - val_loss: 0.4520 - val_accuracy: 0.5068\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 1s 5ms/step - loss: 0.4023 - accuracy: 0.6037 - val_loss: 0.4569 - val_accuracy: 0.5038\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 1s 6ms/step - loss: 0.3862 - accuracy: 0.6276 - val_loss: 0.4625 - val_accuracy: 0.5106\n",
      "Test...\n",
      "42/42 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "\n",
    "max_features = 500\n",
    "maxlen = 30\n",
    "batch_size = 64\n",
    "embedding_dims = 30\n",
    "epochs = 10\n",
    "\n",
    "print('Loading data...')\n",
    "train_path = \"../dataset/preprocessed/netflix_train.csv\"\n",
    "val_path = \"../dataset/preprocessed/netflix_val.csv\"\n",
    "test_path = \"../dataset/preprocessed/netflix_test.csv\"\n",
    "train_df = pd.read_csv(train_path)\n",
    "val_df = pd.read_csv(val_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "x_train = train_df['title'] + \" \" + train_df['description']\n",
    "x_val = val_df['title'] + \" \" + val_df['description']\n",
    "x_test = test_df['title'] + \" \" + test_df['description']\n",
    "\n",
    "y_train = train_df['target_ages']\n",
    "y_val = val_df['target_ages']\n",
    "y_test = test_df['target_ages']\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "x_train = tokenizer.texts_to_sequences(x_train)\n",
    "x_val = tokenizer.texts_to_sequences(x_val)\n",
    "x_test = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_val = pad_sequences(x_val, maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = to_categorical(label_encoder.fit_transform(y_train), num_classes=4)\n",
    "y_test_encoded = to_categorical(label_encoder.transform(y_test), num_classes=4)\n",
    "\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_val), 'validation sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_val shape:', x_val.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Build model...')\n",
    "model = TextCNN(maxlen, max_features, embedding_dims)\n",
    "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, mode='max')\n",
    "model.fit(x_train, y_train_encoded,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          callbacks=[early_stopping],\n",
    "          validation_data=(x_test, y_test_encoded))\n",
    "\n",
    "print('Test...')\n",
    "result = model.predict(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "865d8b2eb28e274047ba64063dfb6a2aabf0dfec4905d304d7a76618dae6fdd4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
